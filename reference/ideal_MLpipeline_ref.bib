@article{rahman2023comparisons,
  title={Comparisons of automated machine learning (AutoML) in predicting whistleblowing of academic dishonesty with demographic and theory of planned behavior},
  author={Rahman, Rahayu Abdul and Masrom, Suraya and Mohamad, Masurah and Sari, Eka Nurmala and Saragih, Fitriani and Abd Rahman, Abdullah Sani},
  journal={MethodsX},
  volume={11},
  pages={102364},
  year={2023},
  publisher={Elsevier}
}

 @article{Sugimura_Hartl_2018, title={Building a Reproducible Machine Learning Pipeline}, DOI={10.48550/arxiv.1810.04570}, abstractNote={Reproducibility of modeling is a problem that exists for any machine learning practitioner, whether in industry or academia. The consequences of an irreproducible model can include significant financial costs, lost time, and even loss of personal reputation (if results prove unable to be replicated). This paper will first discuss the problems we have encountered while building a variety of machine learning models, and subsequently describe the framework we built to tackle the problem of model reproducibility. The framework is comprised of four main components (data, feature, scoring, and evaluation layers), which are themselves comprised of well defined transformations. This enables us to not only exactly replicate a model, but also to reuse the transformations across different models. As a result, the platform has dramatically increased the speed of both offline and online experimentation while also ensuring model reproducibility.}, journal={arXiv}, author={Sugimura, Peter and Hartl, Florian}, year={2018} 
}
 @inproceedings{Garcia_etal_2018, title={Context: The Missing Piece in the Machine Learning Lifecycle}, url={https://rlnsanz.github.io/dat/Flor_CMI_18_CameraReady.pdf}, abstractNote={Machine learning models have become ubiquitous in modern applications. The ML Lifecycle describes a three-phase process used by data scientists and data engineers to develop, train, and serve models. Unfortunately, context around the data, code, people, and systems involved in these pipelines is not captured today. In this paper, we first discuss common pitfalls that missing context creates. Some examples where context is missing include tracking the relationships between code and data and capturing experimental processes over time. We then discuss techniques to address these challenges and briefly mention future work around designing and implementing systems in this space.}, booktitle={KDD}, author={Garcia, Rolando and Sreekanti, Vikram and Yadwadkar, Neeraja and Crankshaw, Daniel and Gonzalez, Joseph E and Hellerstein, Joseph M}, year={2018} 
}


@article{whang2020data,
  title={Data collection and quality challenges for deep learning},
  author={Whang, Steven Euijong and Lee, Jae-Gil},
  journal={Proceedings of the VLDB Endowment},
  volume={13},
  number={12},
  pages={3429--3432},
  year={2020},
  publisher={VLDB Endowment}
}

@article{gudivada2017data,
  title={Data quality considerations for big data and machine learning: Going beyond data cleaning and transformations},
  author={Gudivada, Venkat and Apon, Amy and Ding, Junhua},
  journal={International Journal on Advances in Software},
  volume={10},
  number={1},
  pages={1--20},
  year={2017}
}

@article{roh2019survey,
  title={A survey on data collection for machine learning: a big data-ai integration perspective},
  author={Roh, Yuji and Heo, Geon and Whang, Steven Euijong},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={33},
  number={4},
  pages={1328--1347},
  year={2019},
  publisher={IEEE}
}

@article{ghate2018machine,
  title={Machine learning for data aggregation in WSN: A survey},
  author={Ghate, Vasundhara V and Vijayakumar, Vaidehi},
  journal={International Journal of Pure and Applied Mathematics},
  volume={118},
  number={24},
  pages={1--12},
  year={2018}
}

@article{Golub99, 
title={Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring}, volume={286}, ISSN={0036-8075}, DOI={10.1126/science.286.5439.531}, abstractNote={Although cancer classification has improved over the past 30 years, there has been no general approach for identifying new cancer classes (class discovery) or for assigning tumors to known classes (class prediction). Here, a generic approach to cancer classification based on gene expression monitoring by DNA microarrays is described and applied to human acute leukemias as a test case. A class discovery procedure automatically discovered the distinction between acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) without previous knowledge of these classes. An automatically derived class predictor was able to determine the class of new leukemia cases. The results demonstrate the feasibility of cancer classification based solely on gene expression monitoring and suggest a general strategy for discovering and predicting cancer classes for other types of cancer, independent of previous biological knowledge.}, number={5439}, journal={Science}, author={Golub, T. R. and Slonim, D. K. and Tamayo, P. and Huard, C. and Gaasenbeek, M. and Mesirov, J. P. and Coller, H. and Loh, M. L. and Downing, J. R. and Caligiuri, M. A. and Bloomfield, C. D. and Lander, E. S.}, year={1999}, pages={531–537} 
}

@article{shoket2014research,
  title={Research problem: Identification and formulation},
  author={Shoket, Mohd},
  journal={International Journal of Research},
  volume={1},
  number={4},
  pages={512--518},
  year={2014},
  publisher={Citeseer}
}

@article{elston2022letter,
  title={Letter from the Editor: Faulty generalization},
  author={Elston, Dirk M},
  journal={Journal of the American Academy of Dermatology},
  year={2022},
  publisher={Elsevier}
}

@article{Simone2023, 
title={An overview on the use of AI/ML in Manufacturing MSMEs: solved issues, limits, and challenges}, volume={217}, ISSN={1877-0509}, DOI={10.1016/j.procs.2022.12.382}, abstractNote={Artificial Intelligence (AI) and Machine Learning (ML) represent popular topics of Industry 4.0. The use of these techniques, which are evolving rapidly in both academia and practice, can bring many benefits to production systems, such as enabling resilience and improving sustainable growth. However, given the effort needed in the implementation of AI/ML such as in terms of data quality and employee skills, the potential of AI/ML has not yet fully materialized in the context of manufacturing Micro, Small, and Medium Enterprises (MSMEs), which could improve their core processes or innovate product level to stay competitive, taking advantage of these technologies. This research work, methodologically based on a scoping literature review, presents an investigation of which are the existing applications of AI/ML in manufacturing MSMEs and discusses the limitations and challenges of these technologies. Moreover, the main emerging topics of research and future trends are summarized.}, journal={Procedia Computer Science}, author={Simone, Valentina De and Pasquale, Valentina Di and Miranda, Salvatore}, year={2023}, pages={1820–1829} 
}

@misc{NationalCancerInstitute,
  title = {Cancer Stat Facts: Leukemia},
  year={2000},
  url = {https://seer.cancer.gov/statfacts/html/leuks.html},
  note = {Accessed: 2023-07-23}
}

@article{Barlett2001,
title={Organizational research: Determining appropriate sample size in survey research},
volume={19},
ISBN={15351556},
note={Copyright - Copyright Organizational Systems Research Association Spring 2001; Last updated - 2022-10-20; SubjectsTermNotLitGenreText - United States--US},
number={1},
journal={Information Technology, Learning, and Performance Journal},
author={Barlett,James E. and Kotrlik,Joe W. and Higgins,Chadwick C.},
year={2001},
pages={43-50},
abstract={The determination of sample size is a common task for many organizational researchers. Inappropriate, inadequate, or excessive sample sizes continue to influence the quality and accuracy of research. The procedures for determining sample size for continuous and categorical variables using Cochran's (1977) formulas are described. A discussion and illustration of sample size formulas, including the formula for adjusting the sample size for smaller populations, is included.}
}

@article{Salah2019, 
title={Machine learning applications in the diagnosis of leukemia: Current trends and future directions}, volume={41}, ISSN={1751-5521}, DOI={10.1111/ijlh.13089}, abstractNote={Machine learning (ML) offers opportunities to advance pathological diagnosis, especially with increasing trends in digitalizing microscopic images. Diagnosing leukemia is time-consuming and challenging in many areas globally and there is a growing trend in utilizing ML techniques for its diagnosis. In this review, we aimed to describe the literature of ML utilization in the diagnosis of the four common types of leukemia: acute lymphocytic leukemia (ALL), chronic lymphocytic leukemia (CLL), acute myeloid leukemia (AML), and chronic myelogenous leukemia (CML). Using a strict selection criterion, utilizing MeSH terminology and Boolean logic, an electronic search of MEDLINE and IEEE Xplore Digital Library was performed. The electronic search was complemented by handsearching of references of related studies and the top results of Google Scholar. The full texts of 58 articles were reviewed, out of which, 22 studies were included. The number of studies discussing ALL, AML, CLL, and CML was 12, 8, 3, and 1, respectively. No studies were prospectively applying algorithms in real-world scenarios. Majority of studies had small and homogenous samples and used supervised learning for classification tasks. 91% of the studies were performed after 2010, and 74% of the included studies applied ML algorithms to microscopic diagnosis of leukemia. The included studies illustrated the need to develop the field of ML research, including the transformation from solely designing algorithms to practically applying them clinically.}, number={6}, journal={International Journal of Laboratory Hematology}, author={Salah, Haneen T. and Muhsen, Ibrahim N. and Salama, Mohamed E. and Owaidah, Tarek and Hashmi, Shahrukh K.}, year={2019}, pages={717–725} 
}

@article{Saltz_et_al_2019, title={Integrating Ethics within Machine Learning Courses}, volume={19}, DOI={10.1145/3341164}, abstractNote={This article establishes and addresses opportunities for ethics integration into Machine-learning (ML) courses. Following a survey of the history of computing ethics and the current need for ethical consideration within ML, we consider the current state of ML ethics education via an exploratory analysis of course syllabi in computing programs. The results reveal that though ethics is part of the overall educational landscape in these programs, it is not frequently a part of core technical ML courses. To help address this gap, we offer a preliminary framework, developed via a systematic literature review, of relevant ethics questions that should be addressed within an ML project. A pilot study with 85 students confirms that this framework helped them identify and articulate key ethical considerations within their ML projects. Building from this work, we also provide three example ML course modules that bring ethical thinking directly into learning core ML content. Collectively, this research demonstrates: (1) the need for ethics to be taught as integrated within ML coursework, (2) a structured set of questions useful for identifying and addressing potential issues within an ML project, and (3) novel course models that provide examples for how to practically teach ML ethics without sacrificing core course content. An additional by-product of this research is the collection and integration of recent publications in the emerging field of ML ethics education.}, number={4}, journal={ACM Transactions on Computing Education (TOCE)}, author={Saltz, Jeffrey and Skirpan, Michael and Fiesler, Casey and Gorelick, Micha and Yeh, Tom and Heckman, Robert and Dewar, Neil and Beard, Nathan}, year={2019}, pages={1–26} 
}

@article{Vayena_Blasimme_Cohen_2018, title={Machine learning in medicine: Addressing ethical challenges}, volume={15}, ISSN={1549-1277}, DOI={10.1371/journal.pmed.1002689}, abstractNote={Effy Vayena and colleagues argue that machine learning in medicine must offer data protection, algorithmic transparency, and accountability to earn the trust of patients and clinicians.}, number={11}, journal={PLoS Medicine}, author={Vayena, Effy and Blasimme, Alessandro and Cohen, I. Glenn}, year={2018}, pages={e1002689} 
}

@article{Mukherjee2003, 
title={Estimating Dataset Size Requirements for Classifying DNA Microarray Data}, volume={10}, ISSN={1066-5277}, DOI={10.1089/106652703321825928}, abstractNote={A statistical methodology for estimating dataset size requirements for classifying microarray data using learning curves is introduced. The goal is to use existing classification results to estimate dataset size requirements for future classification experiments and to evaluate the gain in accuracy and significance of classifiers built with additional data. The method is based on fitting inverse power-law models to construct empirical learning curves. It also includes a permutation test procedure to assess the statistical significance of classification performance for a given dataset size. This procedure is applied to several molecular classification problems representing a broad spectrum of levels of complexity.}, number={2}, journal={Journal of Computational Biology}, author={Mukherjee, Sayan and Tamayo, Pablo and Rogers, Simon and Rifkin, Ryan and Engle, Anna and Campbell, Colin and Golub, Todd R. and Mesirov, Jill P.}, year={2003}, pages={119–142} 
}

@article{Dobbin2008, 
title={How Large a Training Set is Needed to Develop a Classifier for Microarray Data?}, volume={14}, ISSN={1078-0432}, DOI={10.1158/1078-0432.ccr-07-0443}, abstractNote={Purpose: A common goal of gene expression microarray studies is the development of a classifier that can be used to divide patients into groups with different prognoses, or with different expected responses to a therapy. These types of classifiers are developed on a training set, which is the set of samples used to train a classifier. The question of how many samples are needed in the training set to produce a good classifier from high-dimensional microarray data is challenging. Experimental Design: We present a model-based approach to determining the sample size required to adequately train a classifier. Results: It is shown that sample size can be determined from three quantities: standardized fold change, class prevalence, and number of genes or features on the arrays. Numerous examples and important experimental design issues are discussed. The method is adapted to address ex post facto determination of whether the size of a training set used to develop a classifier was adequate. An interactive web site for performing the sample size calculations is provided.}, number={1}, journal={Clinical Cancer Research}, author={Dobbin, Kevin K. and Zhao, Yingdong and Simon, Richard M.}, year={2008}, pages={108–114} 
}  

@Manual{golubEsets,
    title = {golubEsets: exprSets for golub leukemia data},
    author = {Todd Golub},
    year = {2023},
    note = {R package version 1.42.0},
    url = {https://bioconductor.org/packages/golubEsets},
    doi = {10.18129/B9.bioc.golubEsets}
}

 @article{Poian_etal_2023, title={Exploratory data analysis (EDA) machine learning approaches for ocean world analog mass spectrometry}, volume={10}, DOI={10.3389/fspas.2023.1134141}, abstractNote={Many upcoming and proposed missions to ocean worlds such as Europa, Enceladus, and Titan aim to evaluate their habitability and the existence of potential life on these moons. These missions will suffer from communication challenges and technology limitations. We review and investigate the applicability of data science and unsupervised machine learning (ML) techniques on isotope ratio mass spectrometry data (IRMS) from volatile laboratory analogs of Europa and Enceladus seawaters as a case study for development of new strategies for icy ocean world missions. Our driving science goal is to determine whether the mass spectra of volatile gases could contain information about the composition of the seawater and potential biosignatures. We implement data science and ML techniques to investigate what inherent information the spectra contain and determine whether a data science pipeline could be designed to quickly analyze data from future ocean worlds missions. In this study, we focus on the exploratory data analysis (EDA) step in the analytics pipeline. This is a crucial unsupervised learning step that allows us to understand the data in depth before subsequent steps such as predictive/supervised learning. EDA identifies and characterizes recurring patterns, significant correlation structure, and helps determine which variables are redundant and which contribute to significant variation in the lower dimensional space. In addition, EDA helps to identify irregularities such as outliers that might be due to poor data quality. We compared dimensionality reduction methods Uniform Manifold Approximation and Projection (UMAP) and Principal Component Analysis (PCA) for transforming our data from a high-dimensional space to a lower dimension, and we compared clustering algorithms for identifying data-driven groups (“clusters”) in the ocean worlds analog IRMS data and mapping these clusters to experimental conditions such as seawater composition and CO2 concentration. Such data analysis and characterization efforts are the first steps toward the longer-term science autonomy goal where similar automated ML tools could be used onboard a spacecraft to prioritize data transmissions for bandwidth-limited outer Solar System missions.}, journal={Frontiers in Astronomy and Space Sciences}, author={Poian, Victoria Da and Theiling, Bethany and Clough, Lily and McKinney, Brett and Major, Jonathan and Chen, Jingyi and Hörst, Sarah}, year={2023}, pages={1134141} 
}

@article{Slonim2000, 
title={Class prediction and discovery using gene expression data}, DOI={10.1145/332306.332564}, abstractNote={Classification of patient samples is a crucial aspect of cancer diagnosis and treatment. We present a method for classifying samples by computational analysis of gene expression data. We consider the classification problem in two parts: class discovery and class prediction. Class discovery refers to the process of dividing samples into reproducible classes that have similar behavior or properties, while class prediction places new samples into already known classes. We describe a method for performing class prediction and illustrate its strength by correctly classifying bone marrow and blood samples from acute leukemia patients. We also describe how to use our predictor to validate newly discovered classes, and we demonstrate how this technique could have discovered the key distinctions among leukemias if they were not already known. This proof-of-concept experiment paves the way for a wealth of future work on the molecular classification and understanding of disease.}, journal={Proceedings of the fourth annual international conference on Computational molecular biology}, author={Slonim, Donna K. and Tamayo, Pablo and Mesirov, Jill P. and Golub, Todd R. and Lander, Eric S.}, year={2000}, pages={263–272} 
}

@article{Mehrabi2021, 
title={A Survey on Bias and Fairness in Machine Learning}, volume={54}, ISSN={0360-0300}, DOI={10.1145/3457607}, abstractNote={With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.}, number={6}, journal={ACM Computing Surveys}, author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram}, year={2021}, pages={1–35} 
} 

 @article{Doupe_Faghmous_Basu_2019, title={Machine Learning for Health Services Researchers}, volume={22}, ISSN={1098-3015}, DOI={10.1016/j.jval.2019.02.012}, abstractNote={ Background Machine learning is increasingly used to predict healthcare outcomes, including cost, utilization, and quality. Objective We provide a high-level overview of machine learning for healthcare outcomes researchers and decision makers. Methods We introduce key concepts for understanding the application of machine learning methods to healthcare outcomes research. We first describe current standards to rigorously learn an estimator, which is an algorithm developed through machine learning to predict a particular outcome. We include steps for data preparation, estimator family selection, parameter learning, regularization, and evaluation. We then compare 3 of the most common machine learning methods: (1) decision tree methods that can be useful for identifying how different subpopulations experience different risks for an outcome; (2) deep learning methods that can identify complex nonlinear patterns or interactions between variables predictive of an outcome; and (3) ensemble methods that can improve predictive performance by combining multiple machine learning methods. Results We demonstrate the application of common machine methods to a simulated insurance claims dataset. We specifically include statistical code in R and Python for the development and evaluation of estimators for predicting which patients are at heightened risk for hospitalization from ambulatory care-sensitive conditions. Conclusions Outcomes researchers should be aware of key standards for rigorously evaluating an estimator developed through machine learning approaches. Although multiple methods use machine learning concepts, different approaches are best suited for different research problems.}, number={7}, journal={Value in Health}, author={Doupe, Patrick and Faghmous, James and Basu, Sanjay}, year={2019}, pages={808–815} 
}

 @article{Shrivastava_Sridharan_2013, title={CONCEPTION OF DATA PREPROCESSING AND PARTITIONING PROCEDURE FOR MACHINE LEARNING ALGORITHM}, volume={1}, ISSN={2347-2812}, url={https://d1wqtxts1xzle7.cloudfront.net/35743410/dataprep-libre.pdf?1417059341=&response-content-disposition=inline%3B+filename%3DCONCEPTION_OF_DATA_PREPROCESSING_AND_PAR.pdf&Expires=1693901124&Signature=eDbc1gbVyy8I4ba5sMKg06TO0HQp12SrdJknNzJQtVku2gtL5GOmeyi596ark9w-NWNTYBnvilJ7pjNDOpW2ZoVjq0Di3hDX7OTLS74ikA6p3XQFZ1ZYDeP7UNb51ia-~K76RmfymezXMaIplIOxzmPJUCQQBOT5OmF9SdrCTGS8j~Yl8wpfovJUTF6aT4mIYIUIUZeB-T9PL6J51q2gGoErCYlCiG9XasEpCXvIKVF2Ka5auh8aTLjaKfYU9Zh5x0B83RC2AM9DXYeUYWnUOo7Gzr1RFcX3mCXGNTISb-89H5SB8QApSChabZqpdf0DS69sLlZ61Y5hIG97Y4FmZA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA}, abstractNote={This paper mainly deals with the preprocessing of the data used as an input for any machine learning algorithm. The main success behind any machine learning algorithm is based on the quality of the input data used. Though many factors affect the success of Machine Learning (ML) on a given task, still the representation and quality of the instance data attributes for the main success of algorithm. If there is much irrelevant and redundant information present or noisy and unreliable data, then knowledge discovery during the training phase is more difficult. It is well known that data preparation and filtering steps take considerable amount of processing time in ML problems. The product of data pre-processing is the final training set. Thus, this paper presents the algorithms for each step of data pre-processing so that one achieves the best performance for their data set.}, number={3}, journal={International Journal of Recent Advances in Engineering & Technology}, author={Shrivastava, Himanshu and Sridharan, Srivatsan}, year={2013}, pages={160–164} }

 @article{Munoz_etal_2020, title={Informative variable identifier: Expanding interpretability in feature selection}, volume={98}, ISSN={0031-3203}, DOI={10.1016/j.patcog.2019.107077}, abstractNote={There is nowadays an increasing interest in discovering relationships among input variables (also called features) from data to provide better interpretability, which yield more confidence in the solution and provide novel insights about the nature of the problem at hand. We propose a novel feature selection method, called Informative Variable Identifier (IVI), capable of identifying the informative variables and their relationships. It transforms the input-variable space distribution into a coefficient-feature space using existing linear classifiers or a more efficient weight generator that we also propose, Covariance Multiplication Estimator (CME). Informative features and their relationships are determined analyzing the joint distribution of these coefficients with resampling techniques. IVI and CME select the informative variables and then pass them on to any linear or nonlinear classifier. Experiments show that the proposed approach can outperform state-of-art algorithms in terms of feature identification capabilities, and even in classification performance when subsequent classifiers are used.}, journal={Pattern Recognition}, author={Muñoz-Romero, Sergio and Gorostiaga, Arantza and Soguero-Ruiz, Cristina and Mora-Jiménez, Inmaculada and Rojo-Álvarez, José Luis}, year={2020}, pages={107077} 
}

 @article{Beigi_etal_2014, title={Towards Effective Feature Selection in Machine Learning-Based Botnet Detection Approaches}, DOI={10.1109/cns.2014.6997492}, abstractNote={Botnets, as one of the most formidable cyber security threats, are becoming more sophisticated and resistant to detection. In spite of specific behaviors each botnet has, there exist adequate similarities inside each botnet that separate its behavior from benign traffic. Several botnet detection systems have been proposed based on these similarities. However, offering a solution for differentiating botnet traffic (even those using same protocol, e.g. IRC) from normal traffic is not trivial. Extraction of features in either host or network level to model a botnet has been one of the most popular methods in botnet detection. A subset of features, usually selected based on some intuitive understanding of botnets, is used by the machine learning algorithms to classify/cluster botnet traffic. These approaches, tested against two or three botnet traces, have mostly showed satisfactory detection results. Even though, their effectiveness in detection of other botnets or real traffic remains in doubt. Additionally, effectiveness of different combination of features in terms of providing more detection coverage has not been fully studied. In this paper we revisit flow-based features employed in the existing botnet detection studies and evaluate their relative effectiveness. To ensure a proper evaluation we create a dataset containing a diverse set of botnet traces and background traffic.}, journal={2014 IEEE Conference on Communications and Network Security}, author={Beigi, Elaheh Biglar and Jazi, Hossein Hadian and Stakhanova, Natalia and Ghorbani, Ali A.}, year={2014}, pages={247–255} 
}

@inproceedings{mujtaba2019ethical,
  title={Ethical considerations in AI-based recruitment},
  author={Mujtaba, Dena F and Mahapatra, Nihar R},
  booktitle={2019 IEEE International Symposium on Technology and Society (ISTAS)},
  pages={1--7},
  year={2019},
  organization={IEEE}
}

@article{Wang_Huang_2006, 
title={Regulation probability method for gene selection}, volume={27}, ISSN={0167-8655}, DOI={10.1016/j.patrec.2005.07.007}, abstractNote={This paper proposes a novel method for gene selection. In the method, the gene regulation, an important mechanism of gene activities, is first introduced, and then the probabilities of gene regulation are estimated. These probabilities can be seen as the gene regulation information and can be used for gene selection. The applications to the leukemia dataset and the colon dataset suggest that our proposed method is effective, efficient, and competitive to the previous methods.}, number={2}, journal={Pattern Recognition Letters}, author={Wang, Hong-Qiang and Huang, De-Shuang}, year={2006}, pages={116–122} 
}  

@inproceedings{howley2005effect,
  title={The effect of principal component analysis on machine learning accuracy with high dimensional spectral data},
  author={Howley, Tom and Madden, Michael G and O’Connell, Marie-Louise and Ryder, Alan G},
  booktitle={International Conference on Innovative Techniques and Applications of Artificial Intelligence},
  pages={209--222},
  year={2005},
  organization={Springer}
}

@article{yang2020hyperparameter,
  title={On hyperparameter optimization of machine learning algorithms: Theory and practice},
  author={Yang, Li and Shami, Abdallah},
  journal={Neurocomputing},
  volume={415},
  pages={295--316},
  year={2020},
  publisher={Elsevier}
}

@article{Pappu_Pardalos_2014, 
title={Clusters, Orders, and Trees: Methods and Applications, In Honor of Boris Mirkin’s 70th Birthday}, ISSN={1931-6828}, DOI={10.1007/978-1-4939-0742-7_8}, abstractNote={Recently, high-dimensional classification problems have been ubiquitous due to significant advances in technology. High dimensionality poses significant statistical challenges and renders many traditional classification algorithms impractical to use. In this chapter, we present a comprehensive overview of different classifiers that have been highly successful in handling high-dimensional data classification problems. We start with popular methods such as Support Vector Machines and variants of discriminant functions and discuss in detail their applications and modifications to several problems in high-dimensional settings. We also examine regularization techniques and their integration to several existing algorithms. We then discuss more recent methods, namely the hybrid classifiers and the ensemble classifiers. Feature selection techniques, as a part of hybrid classifiers, are introduced and their relative merits and drawbacks are examined. Lastly, we describe AdaBoost and Random Forests in the ensemble classifiers and discuss their recent surge as useful algorithms for solving high-dimensional data problems.}, journal={Springer Optimization and Its Applications}, author={Pappu, Vijay and Pardalos, Panos M}, year={2014}, pages={119–150} 
}

@article{Alwosheel_Cranenburgh_Chorus_2018, 
title={Is your dataset big enough? Sample size requirements when using artificial neural networks for discrete choice analysis}, volume={28}, ISSN={1755-5345}, DOI={10.1016/j.jocm.2018.07.002}, abstractNote={Artificial Neural Networks (ANNs) are increasingly used for discrete choice analysis. But, at present, it is unknown what sample size requirements are appropriate when using ANNs in this particular context. This paper fills this knowledge gap: we empirically establish a rule-of-thumb for ANN-based discrete choice analysis based on analyses of synthetic and real data. To investigate the effect of complexity of the data generating process on the minimum required sample size, we conduct extensive Monte Carlo analyses using a series of different model specifications with different levels of model complexity, including RUM and RRM models, with and without random taste parameters. Based on our analyses we advise to use a minimum sample size of fifty times the number of weights in the ANN; it should be noted, that the number of weights is generally much larger than the number of parameters in a discrete choice model. This rule-of-thumb is considerably more conservative than the rule-of-thumb that is most often used in the ANN community, which advises to use at least ten times the number of weights.}, journal={Journal of Choice Modelling}, author={Alwosheel, Ahmad and Cranenburgh, Sander van and Chorus, Caspar G.}, year={2018}, pages={167–182} 
}

@article{raschka2018model,
  title={Model evaluation, model selection, and algorithm selection in machine learning},
  author={Raschka, Sebastian},
  journal={arXiv preprint arXiv:1811.12808},
  year={2018}
}

@article{verboven2012robust,
  title={Robust preprocessing and model selection for spectral data},
  author={Verboven, Sabine and Hubert, Mia and Goos, Peter},
  journal={Journal of Chemometrics},
  volume={26},
  number={6},
  pages={282--289},
  year={2012},
  publisher={Wiley Online Library}
}

@article{fenner2018doi,
  title={Doi registrations for software},
  author={Fenner, Martin},
  journal={Front Matter},
  year={2018}
}

@article{Lippincott_2023, 
title={Dryad news}, 
author={Lippincott, Sarah}, 
year={2023}, 
month={Jul}
} 

 @article{Gentleman_2005, title={Reproducible Research: A Bioinformatics Case Study}, volume={4}, ISSN={2194-6302}, DOI={10.2202/1544-6115.1034}, abstractNote={While scientific research and the methodologies involved have gone through substantial technological evolution the technology involved in the publication of the results of these endeavors has remained relatively stagnant. Publication is largely done in the same manner today as it was fifty years ago. Many journals have adopted electronic formats, however, their orientation and style is little different from a printed document. The documents tend to be static and take little advantage of computational resources that might be available. Recent work, Gentleman and Temple Lang (2003), suggests a methodology and basic infrastructure that can be used to publish documents in a substantially different way. Their approach is suitable for the publication of papers whose message relies on computation. Stated quite simply, Gentleman and Temple Lang (2003) propose a paradigm where documents are mixtures of code and text. Such documents may be self-contained or they may be a component of a compendium which provides the infrastructure needed to provide access to data and supporting software. These documents, or compendiums, can be processed in a number of different ways. One transformation will be to replace the code with its output -- thereby providing the familiar, but limited, static document. In this paper we apply these concepts to a seminal paper in bioinformatics, namely The Molecular Classification of Cancer, Golub et al (1999). The authors of that paper have generously provided data and other information that have allowed us to largely reproduce their results. Rather than reproduce this paper exactly we demonstrate that such a reproduction is possible and instead concentrate on demonstrating the usefulness of the compendium concept itself.}, number={1}, journal={Statistical Applications in Genetics and Molecular Biology}, author={Gentleman, Robert}, year={2005}, pages={Article2} 
}

 @inproceedings{Schroder_Thiele_Lehner_2011, title={Setting Goals and Choosing Metrics for Recommender System Evaluations}, volume={23}, url={https://www.researchgate.net/profile/Maik-Thiele-2/publication/268381252_Setting_Goals_and_Choosing_Metrics_for_Recommender_System_Evaluations/links/595e42e1a6fdccc9b17fcffe/Setting-Goals-and-Choosing-Metrics-for-Recommender-System-Evaluations.pdf}, booktitle={UCERSTI2 workshop at the 5th ACM conference on recommender systems}, author={Schroder, Gunnar and Thiele, Maik and Lehner, Wolfgang}, year={2011}, pages={53} 
}

 @article{Stodden_2009, title={Enabling Reproducible Research: Open Licensing For Scientific Innovation}, ISSN={1521-9615}, url={https://www.stodden.net/papers/ijclp-STODDEN-2009.pdf}, DOI={10.1109/mcse.2009.19}, abstractNote={There is a gap in the current licensing and copyright structure for the growing number of scientists releasing their research publicly, particularly on the Internet. Scientific research produces more scholarship than the final paper: for example, the code, data structures, experimental design and parameters, documentation, and figures, are all important both for communication of the scholarship and replication of the results. US copyright law is a barrier to the sharing of scientific scholarship since it establishes exclusive rights for creators over their work, thereby limiting the ability of others to copy, use, build upon, or alter the research. This is precisely opposite to prevailing scientific norms, which provide both that results be replicated before accepted as knowledge, and that scientific understanding be built upon previous discoveries for which authorship recognition is given. In accordance with these norms and to encourage the release of all scientific scholarship, I propose the Reproducible Research Standard (RRS) both to ensure attribution and facilitate the sharing of scientific works. Using the RRS on all components of scientific scholarship will encourage reproducible scientific investigation, facilitate greater collaboration, and promote engagement of the larger community in scientific learning and discovery.}, number={13}, journal={International Journal of Communications Law and Policy}, author={Stodden, Victoria}, year={2009}, pages={22–46} 
}

 @article{Jamieson_2019, title={Signaling the trustworthiness of science}, volume={116}, ISSN={0027-8424}, DOI={10.1073/pnas.1913039116}, abstractNote={Trust in science increases when scientists and the outlets certifying their work honor science’s norms. Scientists often fail to signal to other scientists and, perhaps more importantly, the public that these norms are being upheld. They could do so as they generate, certify, and react to each other’s findings: for example, by promoting the use and value of evidence, transparent reporting, self-correction, replication, a culture of critique, and controls for bias. A number of approaches for authors and journals would lead to more effective signals of trustworthiness at the article level. These include article badging, checklists, a more extensive withdrawal ontology, identity verification, better forward linking, and greater transparency.}, number={39}, journal={Proceedings of the National Academy of Sciences}, author={Jamieson, Kathleen Hall and McNutt, Marcia and Kiermer, Veronique and Sever, Richard}, year={2019}, pages={19231–19236} 
}

@article{Li2001, 
title={Gene selection for sample classification based on gene expression data: study of sensitivity to choice of parameters of the GA/KNN method}, volume={17}, ISSN={1367-4803}, DOI={10.1093/bioinformatics/17.12.1131}, abstractNote={Motivation: We recently introduced a multivariate approach that selects a subset of predictive genes jointly for sample classification based on expression data. We tested the algorithm on colon and leukemia data sets. As an extension to our earlier work, we systematically examine the sensitivity, reproducibility and stability of gene selection/sample classification to the choice of parameters of the algorithm. Methods: Our approach combines a Genetic Algorithm (GA) and the k-Nearest Neighbor (KNN) method to identify genes that can jointly discriminate between different classes of samples (e.g. normal versus tumor). The GA/KNN method is a stochastic supervised pattern recognition method. The genes identified are subsequently used to classify independent test set samples. Results: The GA/KNN method is capable of selecting a subset of predictive genes from a large noisy data set for sample classification. It is a multivariate approach that can capture the correlated structure in the data. We find that for a given data set gene selection is highly repeatable in independent runs using the GA/KNN method. In general, however, gene selection may be less robust than classification. Availability: The method is available at http://dir.niehs.nih.gov/microarray/datamining Contact: LI3@niehs.nih.gov}, number={12}, journal={Bioinformatics}, author={Li, Leping and Weinberg, Clarice R. and Darden, Thomas A. and Pedersen, Lee G.}, year={2001}, pages={1131–1142} 
}

@article{Dudoit2002, 
title={Comparison of Discrimination Methods for the Classification of Tumors Using Gene Expression Data}, volume={97}, ISSN={0162-1459}, DOI={10.1198/016214502753479248}, abstractNote={A reliable and precise classification of tumors is essential for successful diagnosis and treatment of cancer. cDNA microarrays and high-density oligonucleotide chips are novel biotechnologies increasingly used in cancer research. By allowing the monitoring of expression levels in cells for thousands of genes simultaneously, microarray experiments may lead to a more complete understanding of the molecular variations among tumors and hence to a finer and more informative classification. The ability to successfully distinguish between tumor classes (already known or yet to be discovered) using gene expression data is an important aspect of this novel approach to cancer classification. This article compares the performance of different discrimination methods for the classification of tumors based on gene expression data. The methods include nearest-neighbor classifiers, linear discriminant analysis, and classification trees. Recent machine learning approaches, such as bagging and boosting, are also considered. The discrimination methods are applied to datasets from three recently published cancer gene expression studies.}, number={457}, journal={Journal of the American Statistical Association}, author={Dudoit, Sandrine and Fridlyand, Jane and Speed, Terence P}, year={2002}, pages={77–87} 
}


@article{Yang_et.al_2018, 
title={Grounding Interactive Machine Learning Tool Design in How Non-Experts Actually Build Models}, DOI={10.1145/3196709.3196729}, abstractNote={Machine learning (ML) promises data-driven insights and solutions for people from all walks of life, but the skill of crafting these solutions is possessed by only a few. Emerging research addresses this issue by creating ML tools that are easy and accessible to people who are not formally trained in ML (non-experts). This work investigated how non-experts build ML solutions for themselves in real life. Our interviews and surveys revealed unique potentials of non-expert ML, as well several pitfalls that non-experts are susceptible to. For example, many perceived percentage accuracy as a sole measure of performance, thus problematic models proceeded to deployment. These observations suggested that, while challenging, making ML easy and robust should both be important goals of designing novice-facing ML tools. To advance on this insight, we discuss design implications and created a sensitizing concept to demonstrate how designers might guide non-experts to easily build robust solutions.}, journal={Proceedings of the 2018 Designing Interactive Systems Conference}, author={Yang, Qian and Suh, Jina and Chen, Nan-Chen and Ramos, Gonzalo}, year={2018}, pages={573–584} 
}

@article{Kim_et.al_2017, 
title={Making Machine-Learning Applications for Time-Series Sensor Data Graphical and Interactive}, volume={7}, ISSN={2160-6455}, DOI={10.1145/2983924}, abstractNote={The recent profusion of sensors has given consumers and researchers the ability to collect significant amounts of data. However, understanding sensor data can be a challenge, because it is voluminous, multi-sourced, and unintelligible. Nonetheless, intelligent systems, such as activity recognition, require pattern analysis of sensor data streams to produce compelling results; machine learning (ML) applications enable this type of analysis. However, the number of ML experts able to proficiently classify sensor data is limited, and there remains a lack of interactive, usable tools to help intermediate users perform this type of analysis. To learn which features these tools must support, we conducted interviews with intermediate users of ML and conducted two probe-based studies with a prototype ML and visual analytics system, Gimlets. Our system implements ML applications for sensor-based time-series data as a novel domain-specific prototype that integrates interactive visual analytic features into the ML pipeline. We identify future directions for usable ML systems based on sensor data that will enable intermediate users to build systems that have been prohibitively difficult.}, number={2}, journal={ACM Transactions on Interactive Intelligent Systems (TiiS)}, author={Kim, Seungjun and Tasse, Dan and Dey, Anind K.}, year={2017}, pages={1–30} 
}

@article{Patel_et.al_2008a, 
title={Investigating statistical machine learning as a tool for software development}, DOI={10.1145/1357054.1357160}, abstractNote={As statistical machine learning algorithms and techniques continue to mature, many researchers and developers see statistical machine learning not only as a topic of expert study, but also as a tool for software development. Extensive prior work has studied software development, but little prior work has studied software developers applying statistical machine learning. This paper presents interviews of eleven researchers experienced in applying statistical machine learning algorithms and techniques to human-computer interaction problems, as well as a study of ten participants working during a five-hour study to apply statistical machine learning algorithms and techniques to a realistic problem. We distill three related categories of difficulties that arise in applying statistical machine learning as a tool for software development: (1) difficulty pursuing statistical machine learning as an iterative and exploratory process, (2) difficulty understanding relationships between data and the behavior of statistical machine learning algorithms, and (3) difficulty evaluating the performance of statistical machine learning algorithms and techniques in the context of applications. This paper provides important new insight into these difficulties and the need for development tools that better support the application of statistical machine learning.}, journal={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}, author={Patel, Kayur and Fogarty, James and Landay, James A and Harrison, Beverly}, year={2008}, pages={667–676} 
}

@article{Patel_et.al_2008b, title={Examining Difficulties Software Developers Encounter in the Adoption of Statistical Machine Learning}, volume={3}, url={https://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=0B583EF000AA26F0D365F6627229DD1A?doi=10.1.1.545.4066&rep=rep1&type=pdf}, DOI={10.5555/1620270.1620333}, abstractNote={Statistical machine learning continues to show promise as a tool for addressing complex problems in a variety of domains. An increasing number of developers are therefore looking to use statistical machine learning algorithms within applications. We have conducted two initial studies examining the difficulties that developers encounter when creating a statistical machine learning component of a larger application. We first interviewed researchers with experience integrating statistical machine learning into applications. We then sought to directly observe and quantify some of the behavior described in our interviews using a laboratory study of developers attempting to build a simple application that uses statistical machine learning. This paper presents the difficulties we observed in our studies, discusses current challenges to developer adoption of statistical machine learning, and proposes potential approaches to better supporting developers creating statistical machine learning components of applications.}, journal={Association for the Advancement of Artificial Intelligence}, author={Patel, Kayur and Fogarty, James and Landay, James A. and Harrison, Beverly}, year={2008}, pages={1563–1566} 
}

@book{fenner2019machine,
  title={Machine learning with Python for everyone},
  author={Fenner, Mark},
  year={2019},
  publisher={Addison-Wesley Professional}
}

@article{Matthews_2019, 
title={Machine learning for everyone}, volume={15}, url={https://journals.co.za/doi/abs/10.10520/EJC-18ee95d2ef}, DOI={10.10520/ejc-18ee95d2ef}, abstractNote={It’s how YouTube ….}, journal={Quest}, author={Matthews, Sue}, year={2019}, pages={4} 
}

@article{Stodden_Wu_Sochat_2018, 
title={AIM: AN ABSTRACTION FOR IMPROVING MACHINE LEARNING PREDICTION}, volume={00}, DOI={10.1109/dsw.2018.8439914}, abstractNote={We introduce a structured and portable Abstraction for Improving Machine learning (AIM) to improve prediction outcomes and enable meaningful comparisons of ML pipelines. We implement AIM for a well-known acute leukemia classification problem using the Scientific Filesystem, enabling direct performance comparisons across a variety of classifiers. AIM provides three direct efficiency benefits: 1) the sources of performance differences between ML pipelines can identified at the algorithm implementation level as defined by the AIM, 2) improvements can be made to specific aspects of the pipeline and thus better understood, and 3) the reuse of these defined abstraction components across different pipelines is facilitated. When the AIM is defined at the outset of the prediction challenge, these benefits can come at minimal cost. We show these benefits by implementing AIM and the Scientific Filesystem on the well-known Golub AML/ALL cancer dataset.}, note={AIM.}, journal={2018 IEEE Data Science Workshop (DSW)}, author={Stodden, Victoria and Wu, Xiaomian and Sochat, Vanessa}, year={2018}, pages={1–5} 
}

@article{Leake2003, title={Interactive machine learning}, DOI={10.1145/604045.604056}, abstractNote={Perceptual user interfaces (PUIs) …}, journal={Proceedings of the 8th international conference on Intelligent user interfaces}, author={Leake, David and Johnson, Lewis and Andre, Elisabeth and Fails, Jerry Alan and Olsen, Dan R}, year={2003}, pages={39–45} 
}

@article{Tan_et.al_2011, title={Human model evaluation in interactive supervised learning}, DOI={10.1145/1978942.1978965}, abstractNote={Model evaluation plays ...}, journal={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems}, author={Tan, Desney and Fitzpatrick, Geraldine and Gutwin, Carl and Begole, Bo and Kellogg, Wendy A and Fiebrink, Rebecca and Cook, Perry R and Trueman, Dan}, year={2011}, pages={147–156} 
}

@article{Ko_et.al_2004, 
title={Six Learning Barriers in End-User Programming Systems}, DOI={10.1109/vlhcc.2004.47}, abstractNote={As ...}, journal={2004 IEEE Symposium on Visual Languages - Human Centric Computing}, author={Ko, Andrew J. and Myers, Brad A. and Aung, Htet Htet}, year={2004}, pages={199–206} 
}

@article{national2019reproducibility,
  title={Reproducibility and replicability in science},
  author={National Academies of Sciences, Engineering, and Medicine and others},
  year={2019},
  publisher={National Academies Press}
}

@article{Samuel_et.al_2020_MLpipelines, title={Machine Learning Pipelines: Provenance, Reproducibility and FAIR Data Principles}, DOI={10.48550/arxiv.2006.12117}, abstractNote={Machine learning (ML) is an increasingly important scientific tool supporting decision making and knowledge generation in numerous fields. With this, it also becomes more and more important that the results of ML experiments are reproducible. Unfortunately, that often is not the case. Rather, ML, similar to many other disciplines, faces a reproducibility crisis. In this paper, we describe our goals and initial steps in supporting the end-to-end reproducibility of ML pipelines. We investigate which factors beyond the availability of source code and datasets influence reproducibility of ML experiments. We propose ways to apply FAIR data practices to ML workflows. We present our preliminary results on the role of our tool, ProvBook, in capturing and comparing provenance of ML experiments and their reproducibility using Jupyter Notebooks.}, journal={arXiv}, author={Samuel, Sheeba and Löffler, Frank and König-Ries, Birgitta}, year={2020} 
}

@article{Weide_et.al_2017versioning, title={Versioning for End-to-End Machine Learning Pipelines}, DOI={10.1145/3076246.3076248}, abstractNote={End-to-end machine learning pipelines that run in shared environments are challenging to implement. Production pipelines typically consist of multiple interdependent processing stages. Between stages, the intermediate results are persisted to reduce redundant computation and to improve robustness. Those results might come in the form of datasets for data processing pipelines or in the form of model coefficients in case of model training pipelines. Reusing persisted results improves efficiency but at the same time creates complicated dependencies. Every time one of the processing stages is changed, either due to code change or due to parameters change, it becomes difficult to find which datasets can be reused and which should be recomputed. In this paper we build upon previous work to produce derivations of datasets to ensure that multiple versions of a pipeline can run in parallel while minimizing the amount of redundant computations. Our extensions include partial derivations to simplify navigation and reuse, explicit support for schema changes of pipelines, and a central registry of running pipelines to coordinate upgrading pipelines between teams.}, journal={Proceedings of the 1st Workshop on Data Management for End-to-End Machine Learning}, author={Weide, Tom van der and Papadopoulos, Dimitris and Smirnov, Oleg and Zielinski, Michal and Kasteren, Tim van}, year={2017}, pages={1–9} 
}

@article{Baweja_et.al_2023, title={Opportunities for human factors in machine learning}, volume={6}, DOI={10.3389/frai.2023.1130190}, abstractNote={The field of machine learning and its subfield of deep learning have grown rapidly in recent years. With the speed of advancement, it is nearly impossible for data scientists to maintain expert knowledge of cutting-edge techniques. This study applies human factors methods to the field of machine learning to address these difficulties. Using semi-structured interviews with data scientists at a National Laboratory, we sought to understand the process used when working with machine learning models, the challenges encountered, and the ways that human factors might contribute to addressing those challenges. Results of the interviews were analyzed to create a generalization of the process of working with machine learning models. Issues encountered during each process step are described. Recommendations and areas for collaboration between data scientists and human factors experts are provided, with the goal of creating better tools, knowledge, and guidance for machine learning scientists.}, journal={Frontiers in Artificial Intelligence}, author={Baweja, Jessica A. and Fallon, Corey K. and Jefferson, Brett A.}, year={2023}, pages={1130190} 
}

@article{Muller_et.al_2019how, title={How Data Science Workers Work with Data}, DOI={10.1145/3290605.3300356}, abstractNote={With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices.}, journal={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems}, author={Muller, Michael and Lange, Ingrid and Wang, Dakuo and Piorkowski, David and Tsay, Jason and Liao, Q Vera and Dugan, Casey and Erickson, Thomas}, year={2019}, pages={1–15} 
}

@article{Rosenthal_1979, title={The file drawer problem and tolerance for null results}, volume={86}, ISSN={0033-2909}, DOI={10.1037/0033-2909.86.3.638}, abstractNote={For any given research area, one cannot tell how many studies have been conducted but never reported. The extreme view of the “file drawer problem” is that journals are filled with the 5% of the studies that show Type I errors, while the file drawers are filled with the 95% of the studies that show nonsignificant results. Quantitative procedures for computing the tolerance for filed and future null results are reported and illustrated, and the implications are discussed. (15 ref)}, number={3}, journal={Psychological Bulletin}, author={Rosenthal, Robert}, year={1979}, pages={638–641} 
}

@article{The_newsletter_the_IEA, 
volume={43}, ISSN={0014-0139}, 
DOI={10.1080/00140130050174554}, number={11}, 
journal={Ergonomics}, year={2000}, pages={1939–1945} 
}

@article{Stodden_2020, title={The data science life cycle: a disciplined approach to advancing data science as a science}, volume={63}, ISSN={0001-0782}, DOI={10.1145/3360646}, abstractNote={A cycle that traces ways to define the landscape of data science.}, number={7}, journal={Communications of the ACM}, author={Stodden, Victoria}, year={2020}, pages={58–66} 
}

@article{Krafczyk_et.al_2021, title={Learning from reproducing computational results: introducing three principles and the Reproduction Package}, volume={379}, ISSN={1364-503X}, DOI={10.1098/rsta.2020.0069}, abstractNote={We carry out efforts to reproduce computational results for seven published articles and identify barriers to computational reproducibility.}, number={2197}, journal={Philosophical Transactions of the Royal Society A}, author={Krafczyk, M. S. and Shi, A. and Bhaskar, A. and Marinov, D. and Stodden, V.}, year={2021}, pages={20200069} 
}

@inproceedings{sites2007intensive,
  title={An intensive care specific electronic medical record: Is there transparency?},
  author={Sites, Frank D and Rich, Victoria L and Hanson, C William},
  booktitle={2007 Joint Workshop on High Confidence Medical Devices, Software, and Systems and Medical Device Plug-and-Play Interoperability (HCMDSS-MDPnP 2007)},
  pages={137--139},
  year={2007},
  organization={IEEE}
}

@inproceedings{kumfer2016human,
  title={A human factors perspective on ethical concerns of vehicle automation},
  author={Kumfer, Wesley J and Levulis, Samuel J and Olson, Megan D and Burgess, Richard A},
  booktitle={Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  volume={60},
  number={1},
  pages={1844--1848},
  year={2016},
  organization={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{Hong_2020_HF, title={Human Factors in Model Interpretability: Industry Practices, Challenges, and Needs}, volume={4}, DOI={10.1145/3392878}, abstractNote={As the use of machine learning (ML) models in product development and data-driven decision-making processes became pervasive in many domains, people’s focus on building a well-performing model has increasingly shifted to understanding how their model works...}, number={CSCW1}, journal={Proceedings of the ACM on Human-Computer Interaction}, author={Hong, Sungsoo Ray and Hullman, Jessica and Bertini, Enrico}, year={2020}, pages={1–26} 
}

@article{Simkute_2021Explainability, title={Explainability for experts: A design framework for making algorithms supporting expert decisions more explainable}, volume={7}, ISSN={2666-6596}, DOI={10.1016/j.jrt.2021.100017}, abstractNote={Algorithmic decision support systems are widely applied in domains ranging from healthcare to journalism. To ensure that these systems are fair and accountable, it is essential that humans can maintain meaningful agency, understand and oversee algorithmic processes. Explainability is often seen as a promising mechanism for enabling human-in-the-loop, however, current approaches are ineffective and can lead to various biases. We argue that explainability should be tailored to support naturalistic decision-making and sensemaking strategies employed by domain experts and novices. Based on cognitive psychology and human factors literature review we map potential decision-making strategies dependant on expertise, risk and time dynamics and propose the conceptual Expertise, Risk and Time Explainability framework, intended to be used as explainability design guidelines. Finally, we present a worked example in journalism to illustrate the applicability of our framework in practice.}, journal={Journal of Responsible Technology}, author={Simkute, Auste and Luger, Ewa and Jones, Bronwyn and Evans, Michael and Jones, Rhianne}, year={2021}, pages={100017} 
}

@article{Xie_Lui_2015, title={Incentive Mechanism and Rating System Design for Crowdsourcing Systems: Analysis, Tradeoffs and Inference}, volume={11}, ISSN={1939-1374}, DOI={10.1109/tsc.2016.2539954}, abstractNote={Macrotasking crowdsourcing systems like Elance and Fiverr serve as efficient platforms for requesters to outsource challenging and innovative tasks that require special skills to workers..}, number={1}, journal={IEEE Transactions on Services Computing}, author={Xie, Hong and Lui, John C. S.}, year={2015}, pages={90–102} 
}

@article{Kaye_2016Researcher, title={Researcher-Centered Design of Statistics}, DOI={10.1145/2858036.2858465}, abstractNote={A core tradition of HCI lies in the experimental evaluation of the effects of techniques and interfaces to determine if they are useful for achieving their purpose. These techniques offer the potential for a more user- (i.e. researcher-) centered approach to statistical analysis in HCI.}, journal={Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems}, author={Kaye, Jofish and Druin, Allison and Lampe, Cliff and Morris, Dan and Hourcade, Juan Pablo and Kay, Matthew and Nelson, Gregory L and Hekler, Eric B}, year={2016}, pages={4521–4532} 
}

@article{charness2008role,
  title={The role of expertise research and human factors in capturing, explaining, and producing superior performance},
  author={Charness, Neil and Tuffiash, Michael},
  journal={Human factors},
  volume={50},
  number={3},
  pages={427--432},
  year={2008},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{Sunde_2019Cognitive, 
title={Cognitive and human factors in digital forensics: Problems, challenges, and the way forward}, volume={29}, ISSN={1742-2876}, DOI={10.1016/j.diin.2019.03.011}, abstractNote={Digital forensics is an important and growing forensic domain. Research on miscarriages of justice and misleading evidence, as well as various inquires in the UK and the US, have highlighted human error as an issue within forensic science..}, journal={Digital Investigation}, author={Sunde, Nina and Dror, Itiel E.}, year={2019}, pages={101–108} 
}

@article{norros2007towards,
  title={Towards a theory and method for usability evaluation of complex human-technology systems},
  author={Norros, Leena and Savioja, Paula},
  journal={Activit{\'e}s},
  volume={4},
  number={4-2},
  year={2007},
  publisher={ARPACT-Association Recherches et Pratiques sur les ACTivit{\'e}s}
}

@article{Hopko_2022_HF, 
title={Human Factors Considerations and Metrics in Shared Space Human-Robot Collaboration: A Systematic Review}, volume={9}, DOI={10.3389/frobt.2022.799522}, abstractNote={The degree of successful human-robot collaboration is dependent on the joint consideration of robot factors (RF) and human factors (HF)....}, journal={Frontiers in Robotics and AI}, author={Hopko, Sarah and Wang, Jingkun and Mehta, Ranjana}, year={2022}, pages={799522} 
}

@article{Rachman_Zhang_Ratnayake_2021, 
title={Applications of machine learning in pipeline integrity management: A state-of-the-art review}, volume={193}, ISSN={0308-0161}, DOI={10.1016/j.ijpvp.2021.104471}, abstractNote={Despite being considered the safest means to transport oil and gas, pipelines are susceptible to degradation. Pipeline integrity management (PIM) is implemented to lower the risk of failure due to degradation and to maintain the functionality and safety of pipelines. PIM consists of a set of activities for assessing the operational conditions of pipelines. These activities generate data with high volume, velocity, and variety, due to the length of a pipeline and the number of sensors and tools used to assess the pipeline’s condition. This paper provides a comprehensive review in relation to the applications of machine learning (ML) in managing and processing data generated from PIM activities. ML applications in the elements of a PIM process (e.g., inspection, monitoring, and maintenance) are investigated. The aspects of ML techniques (i.e., type of input, pre-processing, learning algorithm, output and evaluation metric) applied in each element of PIM are examined. Current research challenges and future research opportunities in the application of ML in PIM are also discussed.}, journal={International Journal of Pressure Vessels and Piping}, author={Rachman, Andika and Zhang, Tieling and Ratnayake, R.M. Chandima}, year={2021}, pages={104471} 
}

